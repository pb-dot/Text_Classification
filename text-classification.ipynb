{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n\nimport nltk # for text preprocessing\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n\nimport re\n\nprint(\"Tensorflow Version\",tf.__version__)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-05-30T12:14:22.124330Z","iopub.execute_input":"2023-05-30T12:14:22.124736Z","iopub.status.idle":"2023-05-30T12:14:42.175356Z","shell.execute_reply.started":"2023-05-30T12:14:22.124704Z","shell.execute_reply":"2023-05-30T12:14:42.174069Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nTensorflow Version 2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('../input/sentiment140/training.1600000.processed.noemoticon.csv',\n                 encoding = 'latin',header=None)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:09:50.995113Z","iopub.execute_input":"2023-05-30T12:09:50.995541Z","iopub.status.idle":"2023-05-30T12:09:58.639493Z","shell.execute_reply.started":"2023-05-30T12:09:50.995509Z","shell.execute_reply":"2023-05-30T12:09:58.638331Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   0           1                             2         3                4  \\\n0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n\n                                                   5  \n0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1  is upset that he can't update his Facebook by ...  \n2  @Kenichan I dived many times for the ball. Man...  \n3    my whole body feels itchy and like its on fire   \n4  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.columns = ['sentiment', 'id', 'date', 'query', 'user_id', 'text']# naming columns\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:10:20.829880Z","iopub.execute_input":"2023-05-30T12:10:20.830312Z","iopub.status.idle":"2023-05-30T12:10:20.844272Z","shell.execute_reply.started":"2023-05-30T12:10:20.830270Z","shell.execute_reply":"2023-05-30T12:10:20.843465Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   sentiment          id                          date     query  \\\n0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n           user_id                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>id</th>\n      <th>date</th>\n      <th>query</th>\n      <th>user_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.drop(['id', 'date', 'query', 'user_id'], axis=1)# removing useless columns","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:10:27.917063Z","iopub.execute_input":"2023-05-30T12:10:27.917470Z","iopub.status.idle":"2023-05-30T12:10:30.522321Z","shell.execute_reply.started":"2023-05-30T12:10:27.917439Z","shell.execute_reply":"2023-05-30T12:10:30.520448Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# removing useless columns\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5264\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5405\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5406\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n","\u001b[0;31mKeyError\u001b[0m: \"['id', 'date', 'query', 'user_id'] not found in axis\""],"ename":"KeyError","evalue":"\"['id', 'date', 'query', 'user_id'] not found in axis\"","output_type":"error"}]},{"cell_type":"code","source":"# convert 0 to Negative and 4 to Positive in the \"sentiment\" column\nlab_to_sentiment = {0:\"Negative\", 4:\"Positive\"}\ndef label_decoder(label):\n  return lab_to_sentiment[label]\ndf.sentiment = df.sentiment.apply(lambda x: label_decoder(x))# sentiment is col name\n# x is each element in sentiment col\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:10:36.834118Z","iopub.execute_input":"2023-05-30T12:10:36.834553Z","iopub.status.idle":"2023-05-30T12:10:37.495381Z","shell.execute_reply.started":"2023-05-30T12:10:36.834522Z","shell.execute_reply":"2023-05-30T12:10:37.494419Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"  sentiment                                               text\n0  Negative  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n1  Negative  is upset that he can't update his Facebook by ...\n2  Negative  @Kenichan I dived many times for the ball. Man...\n3  Negative    my whole body feels itchy and like its on fire \n4  Negative  @nationwideclass no, it's not behaving at all....","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Negative</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Negative</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Negative</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Negative</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Negative</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#text precossesing using NLTK lib \nstop_words = stopwords.words('english')\nstemmer = SnowballStemmer('english')\n\ntext_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"#regex to detect all hyperlink","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:10:43.434205Z","iopub.execute_input":"2023-05-30T12:10:43.434844Z","iopub.status.idle":"2023-05-30T12:10:43.446700Z","shell.execute_reply.started":"2023-05-30T12:10:43.434813Z","shell.execute_reply":"2023-05-30T12:10:43.445523Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# re is a python package for regex\n#stemming ,lematization ,remove hyperlink\ndef preprocess(text, stem=False):\n  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n  tokens = []\n  for token in text.split():\n    if token not in stop_words:\n      if stem:\n        tokens.append(stemmer.stem(token))\n      else:\n        tokens.append(token)\n  return \" \".join(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:10:52.841392Z","iopub.execute_input":"2023-05-30T12:10:52.841777Z","iopub.status.idle":"2023-05-30T12:10:52.849419Z","shell.execute_reply.started":"2023-05-30T12:10:52.841749Z","shell.execute_reply":"2023-05-30T12:10:52.848006Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.text = df.text.apply(lambda x: preprocess(x))# x is element of \"text\" col","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:10:57.546013Z","iopub.execute_input":"2023-05-30T12:10:57.546776Z","iopub.status.idle":"2023-05-30T12:12:07.158908Z","shell.execute_reply.started":"2023-05-30T12:10:57.546739Z","shell.execute_reply":"2023-05-30T12:12:07.157669Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df.text\n# for display the column text after processing","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:12:11.090292Z","iopub.execute_input":"2023-05-30T12:12:11.091464Z","iopub.status.idle":"2023-05-30T12:12:11.102001Z","shell.execute_reply.started":"2023-05-30T12:12:11.091402Z","shell.execute_reply":"2023-05-30T12:12:11.100625Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0               awww bummer shoulda got david carr third day\n1          upset update facebook texting might cry result...\n2          dived many times ball managed save 50 rest go ...\n3                           whole body feels itchy like fire\n4                                           behaving mad see\n                                 ...                        \n1599995                        woke school best feeling ever\n1599996             thewdb com cool hear old walt interviews\n1599997                      ready mojo makeover ask details\n1599998    happy 38th birthday boo alll time tupac amaru ...\n1599999    happy charitytuesday thenspcc sparkscharity sp...\nName: text, Length: 1600000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df.head()#display preprocessed data","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:12:16.751428Z","iopub.execute_input":"2023-05-30T12:12:16.752101Z","iopub.status.idle":"2023-05-30T12:12:16.762031Z","shell.execute_reply.started":"2023-05-30T12:12:16.752065Z","shell.execute_reply":"2023-05-30T12:12:16.760713Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"  sentiment                                               text\n0  Negative       awww bummer shoulda got david carr third day\n1  Negative  upset update facebook texting might cry result...\n2  Negative  dived many times ball managed save 50 rest go ...\n3  Negative                   whole body feels itchy like fire\n4  Negative                                   behaving mad see","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Negative</td>\n      <td>awww bummer shoulda got david carr third day</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Negative</td>\n      <td>upset update facebook texting might cry result...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Negative</td>\n      <td>dived many times ball managed save 50 rest go ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Negative</td>\n      <td>whole body feels itchy like fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Negative</td>\n      <td>behaving mad see</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#train and test split and shuffling the dataset\nTRAIN_SIZE = 0.8\nMAX_NB_WORDS = 100000\nMAX_SEQUENCE_LENGTH = 30","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:12:20.258578Z","iopub.execute_input":"2023-05-30T12:12:20.259018Z","iopub.status.idle":"2023-05-30T12:12:20.264469Z","shell.execute_reply.started":"2023-05-30T12:12:20.258983Z","shell.execute_reply":"2023-05-30T12:12:20.263266Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = train_test_split(df, test_size=1-TRAIN_SIZE,\n                                         random_state=7) # Splits Dataset into Training and Testing set\nprint(\"Train Data size:\", len(train_data))\nprint(\"Test Data size\", len(test_data))","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:12:24.470594Z","iopub.execute_input":"2023-05-30T12:12:24.471018Z","iopub.status.idle":"2023-05-30T12:12:25.145477Z","shell.execute_reply.started":"2023-05-30T12:12:24.470985Z","shell.execute_reply":"2023-05-30T12:12:25.144141Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Train Data size: 1280000\nTest Data size 320000\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.head(10)#display","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:12:28.438780Z","iopub.execute_input":"2023-05-30T12:12:28.439195Z","iopub.status.idle":"2023-05-30T12:12:28.451717Z","shell.execute_reply.started":"2023-05-30T12:12:28.439155Z","shell.execute_reply":"2023-05-30T12:12:28.450588Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"        sentiment                                               text\n23786    Negative                                       need friends\n182699   Negative                          im trying call impossible\n476661   Negative  good pace going 3k 13 min missed 5k turn ended...\n1181490  Positive               u gonna shows ny soon luv see u live\n878773   Positive  hell yea get em tattoos ink free wish parents ...\n130866   Negative  yeah need 2 see ur mom calls back first rememb...\n1235876  Positive                           sounds like cup tea sign\n717314   Negative                               tired want sleep wtf\n969880   Positive                                       amazing wish\n748698   Negative  thank god wkrn abc affiliate nashville back mi...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23786</th>\n      <td>Negative</td>\n      <td>need friends</td>\n    </tr>\n    <tr>\n      <th>182699</th>\n      <td>Negative</td>\n      <td>im trying call impossible</td>\n    </tr>\n    <tr>\n      <th>476661</th>\n      <td>Negative</td>\n      <td>good pace going 3k 13 min missed 5k turn ended...</td>\n    </tr>\n    <tr>\n      <th>1181490</th>\n      <td>Positive</td>\n      <td>u gonna shows ny soon luv see u live</td>\n    </tr>\n    <tr>\n      <th>878773</th>\n      <td>Positive</td>\n      <td>hell yea get em tattoos ink free wish parents ...</td>\n    </tr>\n    <tr>\n      <th>130866</th>\n      <td>Negative</td>\n      <td>yeah need 2 see ur mom calls back first rememb...</td>\n    </tr>\n    <tr>\n      <th>1235876</th>\n      <td>Positive</td>\n      <td>sounds like cup tea sign</td>\n    </tr>\n    <tr>\n      <th>717314</th>\n      <td>Negative</td>\n      <td>tired want sleep wtf</td>\n    </tr>\n    <tr>\n      <th>969880</th>\n      <td>Positive</td>\n      <td>amazing wish</td>\n    </tr>\n    <tr>\n      <th>748698</th>\n      <td>Negative</td>\n      <td>thank god wkrn abc affiliate nashville back mi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"\nTokenization \ntokenizer create tokens for every word in the data corpus and map them to a index using dictionary.\n\nword_index contains the index for each word\n\nvocab_size represents the total number of word in the data corpus\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()#create object \ntokenizer.fit_on_texts(train_data.text)\n\n#word_index is the dict that contains (key,value)=(unique word,index)\nword_index = tokenizer.word_index\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Vocabulary Size :\", vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:13:51.588516Z","iopub.execute_input":"2023-05-30T12:13:51.588896Z","iopub.status.idle":"2023-05-30T12:14:17.971684Z","shell.execute_reply.started":"2023-05-30T12:13:51.588866Z","shell.execute_reply":"2023-05-30T12:14:17.970349Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Vocabulary Size : 290575\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.utils import pad_sequences\n#extract and convert only the text col data from datset(train_data)\nx_train = pad_sequences(tokenizer.texts_to_sequences(train_data.text),\n                        maxlen = MAX_SEQUENCE_LENGTH)\nx_test = pad_sequences(tokenizer.texts_to_sequences(test_data.text),\n                       maxlen = MAX_SEQUENCE_LENGTH)\n\nprint(\"Training X Shape:\",x_train.shape)\nprint(\"Testing X Shape:\",x_test.shape)\n\"\"\"\nreprsenting each row of text col in terms of there word_index and fixing the size \nof each row to MAX_SEQUENCE_LENGTH =30 . IE max words in each row of text col is 30\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:17:10.508164Z","iopub.execute_input":"2023-05-30T12:17:10.508625Z","iopub.status.idle":"2023-05-30T12:17:45.977236Z","shell.execute_reply.started":"2023-05-30T12:17:10.508592Z","shell.execute_reply":"2023-05-30T12:17:45.975812Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Training X Shape: (1280000, 30)\nTesting X Shape: (320000, 30)\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'\\nreprsenting each row of text col in terms of there word_index and fixing the size \\nof each row to MAX_SEQUENCE_LENGTH =30 . IE max words in each row of text col is 30'"},"metadata":{}}]},{"cell_type":"code","source":"print(train_data[:2])","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:19:09.579719Z","iopub.execute_input":"2023-05-30T12:19:09.580119Z","iopub.status.idle":"2023-05-30T12:19:09.588804Z","shell.execute_reply.started":"2023-05-30T12:19:09.580091Z","shell.execute_reply":"2023-05-30T12:19:09.587276Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"       sentiment                       text\n23786   Negative               need friends\n182699  Negative  im trying call impossible\n","output_type":"stream"}]},{"cell_type":"code","source":"print(x_train[:2])","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:19:11.984716Z","iopub.execute_input":"2023-05-30T12:19:11.985145Z","iopub.status.idle":"2023-05-30T12:19:11.992203Z","shell.execute_reply.started":"2023-05-30T12:19:11.985113Z","shell.execute_reply":"2023-05-30T12:19:11.990808Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    34  110]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0   18  133\n   220 2319]]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(word_index[\"need\"])\nprint(word_index[\"friends\"])\n\"\"\"\nindex of word need --> 34\nindex of word friends---> 110\nthus the text in train_data[1st row]= \"need friends\" in terms of index = \"34 110\"\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:19:15.166969Z","iopub.execute_input":"2023-05-30T12:19:15.167389Z","iopub.status.idle":"2023-05-30T12:19:15.175684Z","shell.execute_reply.started":"2023-05-30T12:19:15.167356Z","shell.execute_reply":"2023-05-30T12:19:15.174563Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"34\n110\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'\\nindex of word need --> 34\\nindex of word friends---> 110\\nthus the text in train_data[1st row]= \"need friends\" in terms of index = \"34 110\"\\n'"},"metadata":{}}]},{"cell_type":"code","source":"labels = train_data.sentiment.unique().tolist()\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:19:18.931363Z","iopub.execute_input":"2023-05-30T12:19:18.931769Z","iopub.status.idle":"2023-05-30T12:19:19.055010Z","shell.execute_reply.started":"2023-05-30T12:19:18.931739Z","shell.execute_reply":"2023-05-30T12:19:19.053610Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"['Negative', 'Positive']\n","output_type":"stream"}]},{"cell_type":"code","source":"#extract sentiment col(target label) from dataset(train_data) \n#and rename Negative to 0 Positive to 1\nencoder = LabelEncoder()\nencoder.fit(train_data.sentiment.to_list())\n\ny_train = encoder.transform(train_data.sentiment.to_list())\ny_test = encoder.transform(test_data.sentiment.to_list())\n\ny_train = y_train.reshape(-1,1)\ny_test = y_test.reshape(-1,1)\n\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_test shape:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:19:23.119180Z","iopub.execute_input":"2023-05-30T12:19:23.119607Z","iopub.status.idle":"2023-05-30T12:19:25.435467Z","shell.execute_reply.started":"2023-05-30T12:19:23.119575Z","shell.execute_reply":"2023-05-30T12:19:25.434565Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"y_train shape: (1280000, 1)\ny_test shape: (320000, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_data[:1])#contains the processed datset(text,sentiment col)\nprint()\nprint(x_train[:1])# contains text col\nprint()\nprint(y_train[:1])#contains the sentiment col","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:19:29.379064Z","iopub.execute_input":"2023-05-30T12:19:29.379468Z","iopub.status.idle":"2023-05-30T12:19:29.391125Z","shell.execute_reply.started":"2023-05-30T12:19:29.379439Z","shell.execute_reply":"2023-05-30T12:19:29.389734Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"      sentiment          text\n23786  Negative  need friends\n\n[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0  34 110]]\n\n[[0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# another way of reprsentation TF_IDF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\nX_train = vectorizer.fit_transform(train_data.text)\nX_test = vectorizer.transform(test_data.text)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T13:21:49.913322Z","iopub.execute_input":"2023-05-30T13:21:49.913718Z","iopub.status.idle":"2023-05-30T13:22:15.849980Z","shell.execute_reply.started":"2023-05-30T13:21:49.913689Z","shell.execute_reply":"2023-05-30T13:22:15.848989Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nx_train before TF-IDF\n=[  ['i', 'love', 'this', 'movie'],\n    ['this', 'is', 'amazing']\n  ]\nX_train after TF-IDF is of form ((row_index, column_index) tfidf_weight)\n(0, 0)   0.5       # TF-IDF weight for \"i\"\n(0, 1)   0.5       # TF-IDF weight for \"love\"\n(0, 2)   0.5       # TF-IDF weight for \"this\"\n(0, 3)   0.5       # TF-IDF weight for \"movie\"\n\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train[:2])#TF_IDF rep\nprint(x_train[:2])#tokenized rep\nprint(X_test[:2])#TF_IDF rep\nprint(x_test[:2])#tokenized rep\nprint(y_train[:2])\nprint(y_test[:2])","metadata":{"execution":{"iopub.status.busy":"2023-05-30T13:23:47.778360Z","iopub.execute_input":"2023-05-30T13:23:47.779559Z","iopub.status.idle":"2023-05-30T13:23:47.789689Z","shell.execute_reply.started":"2023-05-30T13:23:47.779520Z","shell.execute_reply":"2023-05-30T13:23:47.788530Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"  (0, 96992)\t0.7641979176510755\n  (0, 177570)\t0.6449818157574367\n  (1, 123949)\t0.6762012840602317\n  (1, 45252)\t0.475159191221621\n  (1, 261850)\t0.4451680777268386\n  (1, 123339)\t0.34467513546222067\n[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    34  110]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0   18  133\n   220 2319]]\n  (0, 209676)\t0.538021019612668\n  (0, 146580)\t0.586264045892777\n  (0, 90415)\t0.605663149736202\n  (1, 290031)\t0.3803016310856492\n  (1, 159268)\t0.4875078381967337\n  (1, 147756)\t0.2377540486747114\n  (1, 135380)\t0.4158046904919789\n  (1, 81649)\t0.46649431616325865\n  (1, 54395)\t0.4131214128816957\n[[    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0  1147   934   546]\n [    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n  10560 10126 24285  5739   245 33694]]\n[[0]\n [0]]\n[[0]\n [0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_train.shape)#tf-idf rep\nprint(X_test.shape)\n\nprint(y_train.shape)\nprint(y_test.shape)\n\nprint(x_train.shape)#tokenize rep\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T13:28:59.797947Z","iopub.execute_input":"2023-05-30T13:28:59.798391Z","iopub.status.idle":"2023-05-30T13:28:59.804672Z","shell.execute_reply.started":"2023-05-30T13:28:59.798360Z","shell.execute_reply":"2023-05-30T13:28:59.803785Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"(1280000, 290546)\n(320000, 290546)\n(1280000, 1)\n(320000, 1)\n(1280000, 30)\n(320000, 30)\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"using xg-boost classifier for model training\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\n# Convert the data into DMatrix format for XGBoost\ndtrain = xgb.DMatrix(X_train, label=y_train)#using TF-IDF rep\ndtest = xgb.DMatrix(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:46:15.746572Z","iopub.execute_input":"2023-05-30T12:46:15.746976Z","iopub.status.idle":"2023-05-30T12:46:16.028357Z","shell.execute_reply.started":"2023-05-30T12:46:15.746947Z","shell.execute_reply":"2023-05-30T12:46:16.027469Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Set the XGBoost parameters\nparams = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'logloss',\n    'max_depth': 20,\n    'eta': 0.4,\n    'gamma': 0.2,\n    'subsample': 0.8,\n    'colsample_bytree': 0.8\n}","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:59:11.824170Z","iopub.execute_input":"2023-05-30T12:59:11.824772Z","iopub.status.idle":"2023-05-30T12:59:11.831775Z","shell.execute_reply.started":"2023-05-30T12:59:11.824728Z","shell.execute_reply":"2023-05-30T12:59:11.830443Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Train the XGBoost model\nmodel = xgb.train(params, dtrain,num_boost_round=100)\n\n# Predict the labels for the test set\ny_pred = model.predict(dtest)\ny_pred = [1 if pred >= 0.5 else 0 for pred in y_pred]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T12:59:18.888301Z","iopub.execute_input":"2023-05-30T12:59:18.888724Z","iopub.status.idle":"2023-05-30T13:08:43.072281Z","shell.execute_reply.started":"2023-05-30T12:59:18.888691Z","shell.execute_reply":"2023-05-30T13:08:43.070902Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nf1 = f1_score(y_test, y_pred)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\nprint(\"F1 score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T13:11:17.436118Z","iopub.execute_input":"2023-05-30T13:11:17.437034Z","iopub.status.idle":"2023-05-30T13:11:17.998620Z","shell.execute_reply.started":"2023-05-30T13:11:17.436994Z","shell.execute_reply":"2023-05-30T13:11:17.997490Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Accuracy: 0.498525\nF1 score: 0.6629886467210739\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the metrics of the model\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-05-30T13:09:24.864083Z","iopub.execute_input":"2023-05-30T13:09:24.864832Z","iopub.status.idle":"2023-05-30T13:09:25.506600Z","shell.execute_reply.started":"2023-05-30T13:09:24.864797Z","shell.execute_reply":"2023-05-30T13:09:25.505459Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.51      0.01      0.02    160542\n           1       0.50      0.99      0.66    159458\n\n    accuracy                           0.50    320000\n   macro avg       0.50      0.50      0.34    320000\nweighted avg       0.50      0.50      0.34    320000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#using Naive-Bayes classifier for model training\nfrom sklearn.naive_bayes import MultinomialNB\n# Create a Multinomial Naive Bayes classifier\nclassifier1 = MultinomialNB()\nclassifier2 = MultinomialNB()","metadata":{"execution":{"iopub.status.busy":"2023-05-30T13:39:18.104289Z","iopub.execute_input":"2023-05-30T13:39:18.104776Z","iopub.status.idle":"2023-05-30T13:39:18.110979Z","shell.execute_reply.started":"2023-05-30T13:39:18.104743Z","shell.execute_reply":"2023-05-30T13:39:18.109720Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# Train the classifier\nclassifier1.fit(X_train, y_train)#using TF-IDF rep\nclassifier2.fit(x_train, y_train)#using tokenized rep\n# Predict the labels for the test set\ny_pred1 = classifier1.predict(X_test)\ny_pred2 = classifier2.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T13:39:23.780342Z","iopub.execute_input":"2023-05-30T13:39:23.781040Z","iopub.status.idle":"2023-05-30T13:39:25.837035Z","shell.execute_reply.started":"2023-05-30T13:39:23.781000Z","shell.execute_reply":"2023-05-30T13:39:25.835271Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\ndef fun(y_pred):\n    f1 = f1_score(y_test, y_pred)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"Accuracy:\", accuracy)\n    print(\"F1 score:\", f1)\nprint(f\"TF-idf representation{fun(y_pred1)}\")\nprint(f\"tokenizer representation{fun(y_pred2)}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-30T13:39:31.108063Z","iopub.execute_input":"2023-05-30T13:39:31.108550Z","iopub.status.idle":"2023-05-30T13:39:31.461542Z","shell.execute_reply.started":"2023-05-30T13:39:31.108516Z","shell.execute_reply":"2023-05-30T13:39:31.460054Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Accuracy: 0.762775\nF1 score: 0.7592372929736313\nTF-idf representationNone\nAccuracy: 0.51046875\nF1 score: 0.6114754260997243\ntokenizer representationNone\n","output_type":"stream"}]}]}